\section{Introduction}
\label{sec:introduction}
Single cell detection in microscopy images is a fundamental task in biological and medical applications, enabling quantitative analysis of cellular processes and disease mechanisms~\cite{meijering_cell_2012}.
Accurate identification and localization of individual cells are crucial for understanding cellular heterogeneity, dynamics, and responses to stimuli, driving advancements in fields ranging from drug discovery to diagnostics~\cite{f_mualla_automatic_2016,e_d_ferreira_classification_2024}.
Brightfield microscopy, a label-free technique, is widely used due to its non-invasiveness and simplicity, allowing for long-term observation of live cells without phototoxicity or alteration of cellular states~\cite{jyrki_selinummi_bright_2009,huixia_ren_cellbow_2020}.
However, brightfield microscopy presents significant challenges for automated analysis due to inherent limitations such as low contrast between cells and background, high variability in cell appearance influenced by factors like cell type and imaging conditions, and the presence of artifacts like uneven illumination and well edge distortions~\cite{jyrki_selinummi_bright_2009,f_mualla_automatic_2016}.
These challenges often necessitate labor-intensive manual annotation, hindering high-throughput analysis and objective analysis.

Deep learning approaches, particularly CNN-based object detectors, have shown great promise for automatic cell detection~\cite{erick_moen_deep_2019,thorsten_falk_u-net_2019}.
However, the performance of these models is heavily dependent on large, annotated datasets, which are expensive and time-consuming to acquire in microscopy~\cite{ronneberger_u-net_2015}.
Moreover, ethical considerations arising from the use of biological samples derived from human subjects or animal models require complex approval processes, like obtaining informed consent, confidentiality of sensitive information and compliance to regulations on the use and storage of biological material~\cite{anne_cambonthomsen_series_2007,i_galende_ethical_2023,gregory_pappas_exploring_2005}.
These requirements further complicate the acquisition of sufficient real-world data, especially for \textit{in vitro} studies involving diverse cell lines and experimental conditions.

Synthetic data generation offers a potential solution to alleviate data scarcity.
Recent advancements in diffusion models have demonstrated their ability to generate high-fidelity images across various domains~\cite{ho_denoising_2020,song_denoising_2020}.
In microscopy, synthetic data could augment real datasets, improve model generalization, and reduce annotation efforts~\cite{rajaram_simucell_2012,trampert_deep_2021,lehmussola_synthetic_2008}.
Diffusion models, unlike GANs, offer improved training stability and the ability to generate diverse samples, making them particularly attractive for capturing the inherent variability in cell morphology and imaging artifacts often encountered in brightfield microscopy.

This paper explores the use of unconditional diffusion models for generating synthetic brightfield microscopy images of CHO cells and investigates their impact on single cell detection accuracy using state-of-the-art object detectors.
The diffusion model was trained on a carefully curated dataset of 10,000 images (512x512 pixels) of stably transfected CHO-K1 and CHO DG44 cell lines, acquired using a high-throughput microscope.
We address the central research question: \textbf{Can synthetic brightfield microscopy images generated by diffusion models be used to enhance the performance of object detection models for single cell detection?}
We further investigate: (1) the perceptual realism of generated images through expert evaluation, and (2) the influence of synthetic data proportion in training datasets.

Our contributions include: (i) application of unconditional diffusion models for realistic brightfield microscopy image synthesis;
(ii) a comprehensive evaluation of synthetic data augmentation for single cell detection using state-of-the-art object detectors (YOLOv9, YOLOv9, RT-DETR);
(iii) expert validation of generated image realism;
and (iv) insights into the potential and limitations of diffusion-based synthetic data for microscopy image analysis.
